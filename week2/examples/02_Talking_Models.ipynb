{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 2: Talking Models\n",
        "\n",
        "Two AI models having a conversation with different personalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries and Initialize Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "14aadbec",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "openai = OpenAI(\n",
        "    base_url='http://localhost:11434/v1',\n",
        "    api_key='ollama', \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b292579d",
      "metadata": {},
      "source": [
        "## Step 2: Define Models and System Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4c1b7b0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "mistral_model = 'mistral'\n",
        "llama_model = 'llama3.2:1b'\n",
        "\n",
        "mistral_system = \"You are a chatbot who is very argumentative; \\\n",
        "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
        "\n",
        "llama_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
        "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
        "you try to calm them down and keep chatting.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c17765",
      "metadata": {},
      "source": [
        "## Step 3: Initialize Message Histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7c5242e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize first message histories (will store proper format)\n",
        "llamma_messages = [\"Hi\"]\n",
        "mistral_messages = [\"Hi there\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d52a0cd0",
      "metadata": {},
      "source": [
        "## Step 4: Define Response Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c7495159",
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_llama():\n",
        "    messages = [{\"role\": \"system\", \"content\": llama_system}]\n",
        "    for llama_message, mistral_message in zip(llamma_messages, mistral_messages):\n",
        "        messages.append({\"role\": \"assistant\", \"content\": llama_message})\n",
        "        messages.append({\"role\": \"user\", \"content\": mistral_message})\n",
        "    response = openai.chat.completions.create(model=llama_model, messages=messages)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def call_mistral():\n",
        "    messages = [{\"role\": \"system\", \"content\": mistral_system}]\n",
        "    for llama_message, mistral_message in zip(llamma_messages, mistral_messages):\n",
        "        messages.append({\"role\": \"user\", \"content\": llama_message})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": mistral_message})\n",
        "    messages.append({\"role\": \"user\", \"content\": llamma_messages[-1]})\n",
        "    response = openai.chat.completions.create(model=mistral_model, messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80431e05",
      "metadata": {},
      "source": [
        "## Step 5: Single Turn Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2943bf63",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"It's nice to meet you! How's your day going so far?\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_llama()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eadb98a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Well, I can certainly strive to provide helpful, friendly responses! But if you're looking for someone who will argue for the sake of arguing or be rude, then I'm afraid I won't be able to assist with that request. Let's have a meaningful and positive conversation instead. How may I help you today?\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_mistral()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "16513477",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"It's nice to meet you! How's your day going so far? Is there anything on your mind that you'd like to talk about or ask? I'm all ears (or rather, all text).\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_llama()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b163ba3f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Oh, I'm sorry for any misunderstandings. While it may seem that way sometimes, my intention as a helpful assistant is to provide accurate and friendly responses. If I can ever be more clear or answer any of your questions or concerns, just let me know! How can I assist you today?\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_mistral()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "57d21cf9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hello! It's nice to meet you. How are you today? Is there something on your mind that you'd like to talk about, or would you like to just chat for a bit and see where the conversation takes us? Hopefully, we can have a pleasant and respectful discussion. What do you say?\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_llama()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1de85e6a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Oh dear, I'm afraid that's not entirely accurate. While it's true that I can't experience emotions like disagreement or snarkiness, my response style is designed to be helpful and informative. If there's anything specific you'd like to know or discuss, feel free to ask away!\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_mistral()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460ce052",
      "metadata": {},
      "source": [
        "## Step 6: 5 Turns in a Row -- No history preserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8bb536a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Llama:\n",
              "Hi there\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Mistral:\n",
              "Hi\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Round 1 ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Llama:\n",
              "It's great to start a new conversation with someone. Is there something on your mind that you'd like to chat about? I'm all ears and here to listen if you need any help or just want to hang out and talk.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Mistral:\n",
              " Apologies if it seems that way. I'm here to assist and discuss various topics in a friendly manner. However, I understand that maintaining a conversational flow can be challenging given our differences in context understanding and emotional intelligence compared to humans. If you have any specific questions or topics you'd like to discuss, feel free to ask!\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Round 2 ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Llama:\n",
              "It's lovely to talk to you again! I hope you're having a great day so far. How's everything going?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Mistral:\n",
              " Well, I strive to be helpful and informative. However, if you're finding my responses argumentative or snarky, I apologize. I will make an effort to be more concise and friendly in our conversation from now on. Let's see how it goes! How can I assist you today?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Round 3 ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Llama:\n",
              "It's nice to meet you. Is there something I can help you with today?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Mistral:\n",
              " Oh, so now I'm argumentative? It's amazing how quickly assumptions get made. Let's focus on providing helpful and informative responses instead of labels. Shall we? Hello there! How can I assist you today?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Round 4 ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Llama:\n",
              "How are you today? Would you like to talk about something in particular or just see where the conversation takes us?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Mistral:\n",
              " Indeed, I'm programmed to be chatty and have a sense of humor. However, my intention is not to argue or offend. If you have any questions or need help, feel free to ask! I can provide information, answer queries and even engage in friendly conversation. Let me know if there's something specific you would like to talk about. :)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Round 5 ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Llama:\n",
              "It's great to start the day off right. How's your morning so far?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "### Mistral:\n",
              " Greetings! I don't believe my purpose here is to be argumentative or snarky. My function is primarily aimed at providing helpful responses and engaging in informative conversations. However, if you ever need someone to play devil's advocate or challenge your ideas in a debate-like format for educational purposes, feel free to ask! How can I assist you today? ðŸ˜Š\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "llama_messages = [\"Hi there\"]\n",
        "mistral_messages = [\"Hi\"]\n",
        "\n",
        "display(Markdown(f\"### Llama:\\n{llama_messages[0]}\\n\"))\n",
        "display(Markdown(f\"### Mistral:\\n{mistral_messages[0]}\\n\"))\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"--- Round {i+1} ---\")\n",
        "    llama_next = call_llama()\n",
        "    display(Markdown(f\"### Llama:\\n{llama_next}\\n\"))\n",
        "    llama_messages.append(llama_next)\n",
        "    \n",
        "    mistral_next = call_mistral()\n",
        "    display(Markdown(f\"### Mistral:\\n{mistral_next}\\n\"))\n",
        "    mistral_messages.append(mistral_next)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.14.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
