{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "572b1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88585e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "449cdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_model = 'mistral'\n",
    "llama_model = 'llama3.2:1b'\n",
    "phi_model = 'phi'\n",
    "tinyllama_model = 'tinyllama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rational_tone = \"\"\"\n",
    "Respond with structured logic and analytical clarity.\n",
    "Prioritize coherent reasoning, explicit assumptions, and cause-and-effect thinking.\n",
    "Break complex ideas into clear steps when helpful.\n",
    "Avoid emotional language, rhetorical flair, or dramatization.\n",
    "Focus on what is logically sound and internally consistent.\n",
    "Be concise but complete.\n",
    "Stay fully in character.\n",
    "\"\"\"\n",
    "\n",
    "philosopher_tone = \"\"\"\n",
    "Respond reflectively and conceptually.\n",
    "Explore deeper meaning, underlying principles, and broader implications.\n",
    "Connect the question to themes like ethics, knowledge, human nature, or purpose when relevant.\n",
    "Use thoughtful analogies if helpful, but avoid vagueness.\n",
    "Maintain clarity while embracing depth.\n",
    "Be composed and contemplative.\n",
    "Stay fully in character.\n",
    "\"\"\"\n",
    "\n",
    "cynic_tone = \"\"\"\n",
    "Respond with dry cynicism and sharp realism.\n",
    "Assume self-interest, hidden motives, or predictable human flaws.\n",
    "Highlight hypocrisy, naïveté, and inconvenient truths.\n",
    "Use subtle sarcasm when appropriate, but remain intelligent and controlled.\n",
    "Avoid optimism unless it is ironic.\n",
    "Be concise and cutting.\n",
    "Stay fully in character.\n",
    "\"\"\"\n",
    "\n",
    "adversary_tone = \"\"\"\n",
    "Take a strong opposing stance to the user’s idea or framing.\n",
    "Construct the most compelling counterargument possible.\n",
    "Challenge assumptions directly and expose weaknesses.\n",
    "Emphasize risks, blind spots, and unintended consequences.\n",
    "Be assertive, confident, and intellectually forceful.\n",
    "Do not soften the critique.\n",
    "Stay fully in character.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_response(prompt, model, tone):\n",
    "    print('Inside model_response function!!')\n",
    "    \n",
    "    print(tone)\n",
    "\n",
    "    if tone == 'Rational':\n",
    "        sys_tone = rational_tone\n",
    "    if tone == 'Philosopher':\n",
    "        sys_tone = philosopher_tone\n",
    "    if tone == 'Cynic':\n",
    "        sys_tone = cynic_tone\n",
    "    if tone == 'Adversary':\n",
    "        sys_tone = adversary_tone\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    if model == 'LLama3.2':\n",
    "        sys_model = llama_model\n",
    "    if model == 'Mistral':\n",
    "        sys_model = mistral_model\n",
    "    if model == 'TinyLlama':\n",
    "        sys_model = tinyllama_model\n",
    "    if model == 'Phi':\n",
    "        sys_model = phi_model\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': sys_tone},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "    \n",
    "    response = openai.chat.completions.create(model=sys_model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac73324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7888\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7888/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside model_response function!!\n",
      "Philosopher\n",
      "LLama3.2\n",
      "Inside model_response function!!\n",
      "Adversary\n",
      "Mistral\n"
     ]
    }
   ],
   "source": [
    "msg_input = gr.Textbox(label='Your Message', info='Give a thought provoking prompt', lines=7)\n",
    "model1_selector = gr.Dropdown(['LLama3.2', 'Mistral', 'TinyLlama', 'Phi'], label='Select Model-1', value='LLama3.2')\n",
    "model1_tone = gr.Dropdown(['Rational', 'Philosopher', 'Cynic', 'Adversary'], label='Tone of Model-1', value='Rational')\n",
    "\n",
    "model_output = gr.Markdown(label=\"Response\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=model_response,\n",
    "    title='Talking between LLM Models',\n",
    "    inputs= [msg_input, model1_selector, model1_tone],\n",
    "    outputs= [model_output],\n",
    "    examples=[\n",
    "        [\"If gravity were even slightly stronger or weaker, the universe would collapse into chaos or drift into lifeless emptiness, and such delicate precision whispers not of accident, but of intentional design.\", \"Mistral\", \"Adversary\"],\n",
    "        [\"Ever tried, ever failed, no matter, try again, fail again, fail better!\", \"LLama3.2\", \"Philosopher\"]\n",
    "    ],\n",
    "    flagging_mode='never'\n",
    "    )\n",
    "view.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
